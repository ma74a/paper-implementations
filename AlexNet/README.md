# AlexNet Implementation in PyTorch

A from-scratch implementation of the AlexNet architecture using PyTorch, based on the original 2012 paper "ImageNet Classification with Deep Convolutional Neural Networks" by Krizhevsky et al.

![AlexNet Architecture](alexnetarch.png)

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Project Structure](#project-structure)
- [Requirements](#requirements)
- [Installation](#installation)
- [Dataset Structure](#dataset-structure)
- [Usage](#usage)
- [Configuration](#configuration)
- [Model Architecture](#model-architecture)
- [References](#references)

## âœ¨ Features

- Complete AlexNet architecture implementation
- Custom dataset loader for image classification
- Training and validation pipeline
- Model checkpointing
- Loss and accuracy visualization
- Inference script for predictions
- Configurable hyperparameters

## ğŸ“ Project Structure

```
AlexNet/
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ alexnetarch.png          # Architecture diagram
â”œâ”€â”€ train_model.py           # Main training script
â”œâ”€â”€ predict.py               # Inference script
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py            # AlexNet model definition
â”‚   â”œâ”€â”€ dataset.py          # Custom dataset class
â”‚   â”œâ”€â”€ training.py         # Training and validation logic
â”‚   â””â”€â”€ load_data.py        # Data loading utilities
â””â”€â”€ utils/
    â”œâ”€â”€ config.py           # Configuration settings
    â””â”€â”€ visualize.py        # Plotting utilities
```

## ğŸ“¦ Requirements

- Python 3.8+
- PyTorch 2.0+
- torchvision
- Pillow
- matplotlib
- numpy

## ğŸš€ Installation

1. **Clone the repository** (or navigate to the AlexNet directory):
   ```bash
   cd /path/to/AlexNet
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“‚ Dataset Structure

Organize your dataset in the following structure:

```
your_dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ class1/
â”‚   â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”‚   â”œâ”€â”€ image2.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ class2/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ classN/
â”‚       â””â”€â”€ ...
â””â”€â”€ val/
    â”œâ”€â”€ class1/
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ class2/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ classN/
        â””â”€â”€ ...
```

**Update the dataset paths** in `utils/config.py`:
```python
TRAIN_DATA = "/path/to/your/dataset/train"
VAL_DATA = "/path/to/your/dataset/val"
```

## ğŸ’» Usage

### Training

To train the model:

```bash
python train_model.py
```

This will:
- Load the training and validation datasets
- Initialize the AlexNet model
- Train for the specified number of epochs
- Display training/validation loss and accuracy
- Plot loss curves after training

### Inference

To make predictions on new images:

```python
from src.model import AlexNet
from predict import predict_image
import torch

# Load your trained model
model = AlexNet(num_classes=5)
model.load_state_dict(torch.load('path/to/checkpoint.pth'))
model.eval()

# Make prediction
prediction = predict_image(model, 'path/to/image.jpg')
print(f"Predicted class: {prediction}")
```

## âš™ï¸ Configuration

All hyperparameters and settings are centralized in `utils/config.py`:

```python
class Config:
    # Dataset paths
    TRAIN_DATA = "/path/to/train"
    VAL_DATA = "/path/to/val"
    
    # Hyperparameters
    LEARNING_RATE = 0.01
    BATCH_SIZE = 32
    EPOCHS = 100
    NUM_CLASSES = 5
    IMG_SIZE = 256
    
    # Device
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
```

**Modify these values** according to your dataset and computational resources.

## ğŸ—ï¸ Model Architecture

The implementation follows the original AlexNet architecture:

### Convolutional Layers:
1. **Conv1**: 96 filters, 11Ã—11 kernel, stride 4 â†’ ReLU â†’ LRN â†’ MaxPool
2. **Conv2**: 256 filters, 5Ã—5 kernel, stride 1 â†’ ReLU â†’ LRN â†’ MaxPool
3. **Conv3**: 384 filters, 3Ã—3 kernel, stride 1 â†’ ReLU
4. **Conv4**: 384 filters, 3Ã—3 kernel, stride 1 â†’ ReLU
5. **Conv5**: 256 filters, 3Ã—3 kernel, stride 1 â†’ ReLU â†’ MaxPool

### Fully Connected Layers:
1. **FC1**: 4096 units â†’ ReLU â†’ Dropout(0.5)
2. **FC2**: 4096 units â†’ ReLU â†’ Dropout(0.5)
3. **FC3**: NUM_CLASSES units (output layer)

**Input**: 227Ã—227Ã—3 RGB images  
**Output**: Class probabilities for NUM_CLASSES classes

## ğŸ“Š Training Details

- **Optimizer**: SGD with momentum (0.9) and weight decay (0.0005)
- **Loss Function**: Cross-Entropy Loss
- **Data Augmentation**:
  - Random horizontal flip
  - Random crop (227Ã—227)
  - Normalization (ImageNet statistics)

## ğŸ“– References

- **Original Paper**: [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
- **Authors**: Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton
- **Year**: 2012

## ğŸ“ Notes

- The model expects input images of size 227Ã—227 (after cropping from 256Ã—256)
- Local Response Normalization (LRN) is used as in the original paper
- Adjust `BATCH_SIZE` based on your GPU memory
- Training on CPU will be significantly slower

## ğŸ¤ Contributing

Feel free to open issues or submit pull requests for improvements!

## ğŸ“„ License

This implementation is for educational purposes.
